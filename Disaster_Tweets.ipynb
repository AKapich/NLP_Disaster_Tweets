{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d96d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "940fbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2e664c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07686e",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120dfe3",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "187a968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11c39a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    df['tokenized_text'] =  df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "063f4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(train)\n",
    "tokenize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4b467a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Our, Deeds, are, the, Reason, of, this, #, ea...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, ., Canada]\n",
       "2       [All, residents, asked, to, 'shelter, in, plac...\n",
       "3       [13,000, people, receive, #, wildfires, evacua...\n",
       "4       [Just, got, sent, this, photo, from, Ruby, #, ...\n",
       "                              ...                        \n",
       "7608    [Two, giant, cranes, holding, a, bridge, colla...\n",
       "7609    [@, aria_ahrary, @, TheTawniest, The, out, of,...\n",
       "7610    [M1.94, [, 01:04, UTC, ], ?, 5km, S, of, Volca...\n",
       "7611    [Police, investigating, after, an, e-bike, col...\n",
       "7612    [The, Latest, :, More, Homes, Razed, by, North...\n",
       "Name: tokenized_text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokenized_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b5dfd",
   "metadata": {},
   "source": [
    "## Removing punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17dbe424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8212c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(df):\n",
    "    df['only_text'] = df['tokenized_text'].apply(\n",
    "        lambda row: [word for word in row if word not in punctuation]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e597472",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation(train)\n",
    "remove_punctuation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d62ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Our, Deeds, are, the, Reason, of, this, earth...\n",
       "1           [Forest, fire, near, La, Ronge, Sask, Canada]\n",
       "2       [All, residents, asked, to, 'shelter, in, plac...\n",
       "3       [13,000, people, receive, wildfires, evacuatio...\n",
       "4       [Just, got, sent, this, photo, from, Ruby, Ala...\n",
       "                              ...                        \n",
       "7608    [Two, giant, cranes, holding, a, bridge, colla...\n",
       "7609    [aria_ahrary, TheTawniest, The, out, of, contr...\n",
       "7610    [M1.94, 01:04, UTC, 5km, S, of, Volcano, Hawai...\n",
       "7611    [Police, investigating, after, an, e-bike, col...\n",
       "7612    [The, Latest, More, Homes, Razed, by, Northern...\n",
       "Name: only_text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['only_text'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015502e",
   "metadata": {},
   "source": [
    "## Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d67b2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7ef4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df):\n",
    "    df['cleaned_text'] = df['only_text'].apply(\n",
    "        lambda row: [word for word in row if word not in stop_words]\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2b1b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords(train)\n",
    "remove_stopwords(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b73b65d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Our, Deeds, Reason, earthquake, May, ALLAH, F...\n",
       "1           [Forest, fire, near, La, Ronge, Sask, Canada]\n",
       "2       [All, residents, asked, 'shelter, place, notif...\n",
       "3       [13,000, people, receive, wildfires, evacuatio...\n",
       "4       [Just, got, sent, photo, Ruby, Alaska, smoke, ...\n",
       "                              ...                        \n",
       "7608    [Two, giant, cranes, holding, bridge, collapse...\n",
       "7609    [aria_ahrary, TheTawniest, The, control, wild,...\n",
       "7610    [M1.94, 01:04, UTC, 5km, S, Volcano, Hawaii, h...\n",
       "7611    [Police, investigating, e-bike, collided, car,...\n",
       "7612    [The, Latest, More, Homes, Razed, Northern, Ca...\n",
       "Name: cleaned_text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cleaned_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fcdd0",
   "metadata": {},
   "source": [
    "# Extracting more information from the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69959c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>only_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #, ea...</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, earth...</td>\n",
       "      <td>[Our, Deeds, Reason, earthquake, May, ALLAH, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, ., Canada]</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, Canada]</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, Canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[All, residents, asked, to, 'shelter, in, plac...</td>\n",
       "      <td>[All, residents, asked, to, 'shelter, in, plac...</td>\n",
       "      <td>[All, residents, asked, 'shelter, place, notif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[13,000, people, receive, #, wildfires, evacua...</td>\n",
       "      <td>[13,000, people, receive, wildfires, evacuatio...</td>\n",
       "      <td>[13,000, people, receive, wildfires, evacuatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, #, ...</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, Ala...</td>\n",
       "      <td>[Just, got, sent, photo, Ruby, Alaska, smoke, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Two, giant, cranes, holding, a, bridge, colla...</td>\n",
       "      <td>[Two, giant, cranes, holding, a, bridge, colla...</td>\n",
       "      <td>[Two, giant, cranes, holding, bridge, collapse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[@, aria_ahrary, @, TheTawniest, The, out, of,...</td>\n",
       "      <td>[aria_ahrary, TheTawniest, The, out, of, contr...</td>\n",
       "      <td>[aria_ahrary, TheTawniest, The, control, wild,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[M1.94, [, 01:04, UTC, ], ?, 5km, S, of, Volca...</td>\n",
       "      <td>[M1.94, 01:04, UTC, 5km, S, of, Volcano, Hawai...</td>\n",
       "      <td>[M1.94, 01:04, UTC, 5km, S, Volcano, Hawaii, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Police, investigating, after, an, e-bike, col...</td>\n",
       "      <td>[Police, investigating, after, an, e-bike, col...</td>\n",
       "      <td>[Police, investigating, e-bike, collided, car,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, Latest, :, More, Homes, Razed, by, North...</td>\n",
       "      <td>[The, Latest, More, Homes, Razed, by, Northern...</td>\n",
       "      <td>[The, Latest, More, Homes, Razed, Northern, Ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "0     [Our, Deeds, are, the, Reason, of, this, #, ea...   \n",
       "1      [Forest, fire, near, La, Ronge, Sask, ., Canada]   \n",
       "2     [All, residents, asked, to, 'shelter, in, plac...   \n",
       "3     [13,000, people, receive, #, wildfires, evacua...   \n",
       "4     [Just, got, sent, this, photo, from, Ruby, #, ...   \n",
       "...                                                 ...   \n",
       "7608  [Two, giant, cranes, holding, a, bridge, colla...   \n",
       "7609  [@, aria_ahrary, @, TheTawniest, The, out, of,...   \n",
       "7610  [M1.94, [, 01:04, UTC, ], ?, 5km, S, of, Volca...   \n",
       "7611  [Police, investigating, after, an, e-bike, col...   \n",
       "7612  [The, Latest, :, More, Homes, Razed, by, North...   \n",
       "\n",
       "                                              only_text  \\\n",
       "0     [Our, Deeds, are, the, Reason, of, this, earth...   \n",
       "1         [Forest, fire, near, La, Ronge, Sask, Canada]   \n",
       "2     [All, residents, asked, to, 'shelter, in, plac...   \n",
       "3     [13,000, people, receive, wildfires, evacuatio...   \n",
       "4     [Just, got, sent, this, photo, from, Ruby, Ala...   \n",
       "...                                                 ...   \n",
       "7608  [Two, giant, cranes, holding, a, bridge, colla...   \n",
       "7609  [aria_ahrary, TheTawniest, The, out, of, contr...   \n",
       "7610  [M1.94, 01:04, UTC, 5km, S, of, Volcano, Hawai...   \n",
       "7611  [Police, investigating, after, an, e-bike, col...   \n",
       "7612  [The, Latest, More, Homes, Razed, by, Northern...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     [Our, Deeds, Reason, earthquake, May, ALLAH, F...  \n",
       "1         [Forest, fire, near, La, Ronge, Sask, Canada]  \n",
       "2     [All, residents, asked, 'shelter, place, notif...  \n",
       "3     [13,000, people, receive, wildfires, evacuatio...  \n",
       "4     [Just, got, sent, photo, Ruby, Alaska, smoke, ...  \n",
       "...                                                 ...  \n",
       "7608  [Two, giant, cranes, holding, bridge, collapse...  \n",
       "7609  [aria_ahrary, TheTawniest, The, control, wild,...  \n",
       "7610  [M1.94, 01:04, UTC, 5km, S, Volcano, Hawaii, h...  \n",
       "7611  [Police, investigating, e-bike, collided, car,...  \n",
       "7612  [The, Latest, More, Homes, Razed, Northern, Ca...  \n",
       "\n",
       "[7613 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2358399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hashtags(df):\n",
    "    df['#_amount'] = df['tokenized_text'].apply(lambda row: len([word for word in row if word=='#']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd0f45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_hashtags(train)\n",
    "count_hashtags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5162022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mentions(df):\n",
    "    df['@_amount'] = df['tokenized_text'].apply(lambda row: len([word for word in row if word=='@']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc8b1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mentions(train)\n",
    "count_mentions(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db8b24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuation(df):\n",
    "    df['punctuation_amount'] = df['tokenized_text'].apply(\n",
    "        lambda row: len([word for word in row if word in punctuation])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7548955",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_punctuation(train)\n",
    "count_punctuation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8b88f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(df):\n",
    "    df['stopword_amount'] = df['tokenized_text'].apply(\n",
    "        lambda row: len([word for word in row if word in stop_words])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2585ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_stopwords(train)\n",
    "count_stopwords(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5842646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_urls(df):\n",
    "    df['url_amount'] = df['tokenized_text'].apply(\n",
    "        lambda row: len([word for word in row if 'http' in word or 'https' in word])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d16fa8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_urls(train)\n",
    "count_urls(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "281f0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_word_length(df):\n",
    "    df['mean_word_length'] = df['only_text'].apply(\n",
    "        lambda row: round(np.mean([len(word) for word in row]), 3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5c4d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_word_length(train)\n",
    "mean_word_length(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4190b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_amount(df):\n",
    "    df['word_amount'] = df['only_text'].apply(\n",
    "        lambda row: len(row)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54b7d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_amount(train)\n",
    "word_amount(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f736cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_word_amount(df):\n",
    "    df['unique_word_amount'] = df['only_text'].apply(\n",
    "        lambda row: len(list(set(row)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d417b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_amount(train)\n",
    "unique_word_amount(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18164110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104b06fd97044723a99c2c4d0ae53b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab3b2fb146c4e10b261665b4b994faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5341e5a638934e8f9e059fb9ef456b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab83121a90284690a9ff559a90568099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(train.sample(frac=0.1), title=\"Twitter Profiling Report\", explorative=True)\n",
    "profile.to_file(\"twitter.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7cd96",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3af1eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['target']\n",
    "X_train = train.drop(['tokenized_text', 'only_text', 'cleaned_text',\n",
    "                      'keyword', 'location', 'text', 'target', 'id'], axis=1)\n",
    "X_test = test.drop(['tokenized_text', 'only_text', 'cleaned_text',\n",
    "                    'keyword', 'location', 'text', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "63b175c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=120)\n",
    "rf_model.fit(X_train, y_train)\n",
    "RandomForestClassifier(n_estimators=120)\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d1f53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(test['id'])\n",
    "y_pred = pd.DataFrame ({'id':indices,\n",
    "                        'target':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "64d3044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
